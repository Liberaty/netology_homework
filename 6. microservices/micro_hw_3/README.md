# Домашнее задание к занятию «Микросервисы: подходы» - Лепишин Алексей

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

**Решение**

Для обеспечения процесса разработки в микросервисной архитектуре с учетом всех указанных требований предлагаю следующее решение:  
**1. Система контроля версий**: GitHub или GitLab
Причины выбора:
- Полноценная поддержка Git
- Облачная SaaS-версия (GitHub.com / GitLab.com)
- Возможность создания отдельных репозиториев для каждого сервиса
- Интеграция с CI/CD системами через webhooks
- Дополнительные фичи: Issues, MR/PR, Code Review

2. **CI/CD система**: GitLab CI/CD (если выбран GitLab) или GitHub Actions + ArgoCD (если выбран GitHub)  
Вариант 1: GitLab CI/CD  
  Преимущества:  
- Встроенное решение (если используем GitLab)
- Поддержка всех требований из задания:
  - Запуск по push/merge и по кнопке (Manual pipelines)
  - Переменные сборки (включая защищенные)
  - Шаблоны через include и extends
  - Несколько конфигураций через разные файлы .gitlab-ci.yml или ветки
  - Кастомные шаги в job'ах
  - Поддержка Docker-образов для сборки
  - Возможность развернуть собственные раннеры (в т.ч. autoscaling через Docker+machine)
  - Параллельные job'ы и stages
  - Параллельное выполнение тестов через разделение матрицы тестов

Вариант 2: GitHub Actions + ArgoCD  
  GitHub Actions для CI:
- Workflows по событиям GitHub
- Manual triggers через workflow_dispatch
- Secrets management
- Матричные сборки
- Self-hosted runners
- Параллельные job'ы

  ArgoCD для CD:
- GitOps подход
- Автоматический деплой при изменении манифестов
- Визуализация состояния

3. **Хранение секретов**: HashiCorp Vault + интеграция с CI/CD  
Для более сложных случаев (ротация секретов, динамические секреты)  
Альтернативно: встроенные секреты GitLab/GitHub  

4. **Артефакты и Docker-образы**: GitHub Container Registry / GitLab Container Registry или Artifactory  
Хранение собственных образов для сборки  
Хранение релизных артефактов  

5. **Инфраструктура для агентов**:
Kubernetes для запуска self-hosted раннеров (GitLab) или действий (GitHub)  
Автомасштабирование по нагрузке  
Возможность специфических образов для разных типов сборок  

**Обоснование архитектуры:**   
Облачная система: GitLab.com/GitHub.com + их CI/CD - это облачные SaaS решения  
Git-репозитории: Оба решения предоставляют отличную Git-интеграцию  
Гибкость сборок:  
- В GitLab CI/CD через .gitlab-ci.yml с include/extends
- В GitHub Actions через workflow-файлы и матрицы  
Безопасность:  
- Встроенные секреты + возможность интеграции с Vault
- Изоляция сред через разные раннеры
Параллелизм:
- Обе системы поддерживают параллельное выполнение job'ов
- Тесты можно разделить на параллельные задачи
Docker-образы:
- Возможность указывать любой образ для сборки
- Поддержка собственных registry

**Рекомендация**
GitLab Ultimate (если бюджет позволяет) предоставляет наиболее полное решение "из коробки":
- Единая платформа для VCS и CI/CD
- Встроенный container registry
- Advanced features для безопасности и compliance
- Хорошая масштабируемость через Kubernetes раннеры

Для более open-source подхода можно использовать GitHub + Actions + ArgoCD, но потребуется больше интеграционной работы.

---

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

**Решение**  

Стек:
- Vector – сбор, обработка и транспортировка логов
- Kafka – буферизация и гарантированная доставка
- Elasticsearch – хранение и индексация
- Kibana – визуализация и поиск

Архитектура решения:  
Микросервисы → stdout/stderr → Vector (агент) → Kafka → Elasticsearch → Kibana  

Краткое описание работы:
1) Vector собирает логи из stdout контейнеров и отправляет в Kafka
2) Kafka временно хранит логи и обеспечивает надежную доставку
3) Vector (или встроенный коннектор Kafka) забирает логи из Kafka и отправляет в Elasticsearch
4) Kibana предоставляет интерфейс для поиска и анализа логов

Гарантии доставки:  
Vector подтверждает успешную запись в Kafka  
Kafka сохраняет данные до их обработки Elasticsearch  
Elasticsearch реплицирует данные между узлами  

Покрытие требований:  
- Сбор из stdout:	Vector docker_logs source  
- Централизованное хранилище:	Elasticsearch  
- Гарантированная доставка:	Vector + Kafka  
- Поиск и фильтрация:	Elasticsearch + Kibana  
- UI для разработчиков:	Kibana  
- Ссылки на поисковые запросы:	Kibana Saved Searches  


Предложенное решение (Vector → Kafka → Elasticsearch → Kibana):  
- Обеспечивает надежный сбор логов с минимальным влиянием на приложения
- Гарантирует доставку данных даже при сбоях
- Предоставляет удобный интерфейс для разработчиков
- Легко масштабируется при росте нагрузки

Этот стек хорошо зарекомендовал себя в production-средах и покрывает все указанные требования.

---

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

**Решение**  

Основной стек технологий:  
- Prometheus - сбор и хранение метрик
- Grafana - визуализация и дашборды
- Node Exporter - сбор метрик хостов
- cAdvisor - сбор метрик контейнеров
- Специфичные экспортеры - для сервис-специфичных метрик

Функциональность компонентов:
1) Prometheus - сбор и хранение временных рядов метрик:
- Service Discovery для автоматического обнаружения целей
- Мощный язык запросов PromQL
2) Grafana - Визуализация метрик:
- Настраиваемые дашборды
- Создание сложных запросов и агрегаций
- Интерактивные переменные в дашбордах
3) Node Exporter - сбор метрик состояния хостов:
- CPU: использование, нагрузка
- RAM: использование, swap
- HDD: место, IOPS, задержки
- Network: трафик, ошибки, соединения
4) cAdvisor - мониторинг ресурсов контейнеров:
- Использование CPU/RAM
- Дисковые операции
- Сетевой трафик

Покрытие требований:  
- Сбор метрик со всех хостов:	Node Exporter + Prometheus  
- Метрики ресурсов хостов: Node Exporter  
- Метрики ресурсов сервисов: cAdvisor  
- Специфичные метрики сервисов:	Индивидуальные экспортеры  
- UI для запросов и агрегации: Grafana + PromQL  
- Настраиваемые панели мониторинга:	Grafana dashboards  

Преимущества решения:  
- Полнота данных - охват всех уровней инфраструктуры
- Масштабируемость - подходит для растущих систем
- Гибкость - возможность добавлять новые метрики
- Открытый исходный код - отсутствие лицензионных ограничений
- Интеграция - поддержка большинства современных технологий